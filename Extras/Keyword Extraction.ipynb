{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword extraction with `TfidfVectorizer`\n",
    "\n",
    "Scikit-learn's `CountVectorizer` class creates matrices of word counts and is frequently uses in text-classification tasks. The related [`TfidfVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) class creates matrices of [term freqeuency-inverse document frequency](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) (Tf-Idf) values that reflect not just the presence of individual words, but each word's importance. One use for `TfidfVectorizer` is extracting keywords from documents. Let's use it to extract keywords from a book chapter on machine learning. Begin by loading the chapter from a text file and showing the first few paragraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Software developers are accustomed to solving problems algorithmically. Given a recipe, or algorithm, it's not difficult to write an app that hashes a password or computes a monthly mortgage payment. You code up the algorithm, feed it input, and receive output in return. It's another proposition altogether to write code that determines whether a photo contains a cat or a dog. You can try to do it algorithmically, but the minute you get it working, I'll send you a cat or dog picture that breaks the algorithm.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Machine learning takes a different approach to turning input into output. Rather than rely on you to implement an algorithm, it examines a dataset consisting of inputs and outputs and learns how to generate output of its own. Under the hood, special algorithms called learning algorithms build mathematical models of the data and codify the relationship between data going in and data coming out. Once trained in this manner, a model can accept new inputs and generate outputs consistent with the ones in the training data.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To use machine learning to distinguish between cats and dogs, you don't code a cat-vs-dog algorithm. Instead, you train a machine-learning model with cat and dog photos. Success depends on the learning algorithm used and the quality and volume of the training data. Part of becoming a machine-learning engineer is familiarizing yourself with the various learning algorithms and developing an intuition for when to use one versus another. That intuition begins with an examination of machine learning itself.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is Machine Learning?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>At an existential level, machine learning (ML) is a means for finding patterns in numbers and exploiting those patterns to make predictions. Train a model with thousands (or millions) of xs and ys, and let it learn from the data so that given a new x, it can predict what y will be. Learning is the process by which ML finds patterns that can be used to predict future outputs, and it's where the 'learning' in 'machine learning' comes from.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             0\n",
       "0            Software developers are accustomed to solving problems algorithmically. Given a recipe, or algorithm, it's not difficult to write an app that hashes a password or computes a monthly mortgage payment. You code up the algorithm, feed it input, and receive output in return. It's another proposition altogether to write code that determines whether a photo contains a cat or a dog. You can try to do it algorithmically, but the minute you get it working, I'll send you a cat or dog picture that breaks the algorithm.\n",
       "1  Machine learning takes a different approach to turning input into output. Rather than rely on you to implement an algorithm, it examines a dataset consisting of inputs and outputs and learns how to generate output of its own. Under the hood, special algorithms called learning algorithms build mathematical models of the data and codify the relationship between data going in and data coming out. Once trained in this manner, a model can accept new inputs and generate outputs consistent with the ones in the training data.\n",
       "2                  To use machine learning to distinguish between cats and dogs, you don't code a cat-vs-dog algorithm. Instead, you train a machine-learning model with cat and dog photos. Success depends on the learning algorithm used and the quality and volume of the training data. Part of becoming a machine-learning engineer is familiarizing yourself with the various learning algorithms and developing an intuition for when to use one versus another. That intuition begins with an examination of machine learning itself.\n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    What is Machine Learning?\n",
       "4                                                                                    At an existential level, machine learning (ML) is a means for finding patterns in numbers and exploiting those patterns to make predictions. Train a model with thousands (or millions) of xs and ys, and let it learn from the data so that given a new x, it can predict what y will be. Learning is the process by which ML finds patterns that can be used to predict future outputs, and it's where the 'learning' in 'machine learning' comes from."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Data/chapter-1.txt', sep='\\n', header=None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize the paragraphs and show the first few lines of the resulting word matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000 000</th>\n",
       "      <th>000 columns</th>\n",
       "      <th>000 rows</th>\n",
       "      <th>10 years</th>\n",
       "      <th>120 rows</th>\n",
       "      <th>1s 0s</th>\n",
       "      <th>20 data</th>\n",
       "      <th>80 20</th>\n",
       "      <th>accurate model</th>\n",
       "      <th>add column</th>\n",
       "      <th>...</th>\n",
       "      <th>use scikit</th>\n",
       "      <th>used regression</th>\n",
       "      <th>using nearest</th>\n",
       "      <th>versicolor virginica</th>\n",
       "      <th>want predict</th>\n",
       "      <th>web site</th>\n",
       "      <th>width cm</th>\n",
       "      <th>world datasets</th>\n",
       "      <th>xs ys</th>\n",
       "      <th>years experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.420631</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.668611</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32221</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.329341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.553819</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.553819</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.484482</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 187 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    000 000  000 columns  000 rows  10 years  120 rows     1s 0s  20 data  \\\n",
       "0  0.000000          0.0  0.000000       0.0       0.0  0.000000      0.0   \n",
       "1  0.000000          0.0  0.000000       0.0       0.0  0.000000      0.0   \n",
       "2  0.000000          0.0  0.000000       0.0       0.0  0.000000      0.0   \n",
       "3  0.000000          0.0  0.000000       0.0       0.0  0.000000      0.0   \n",
       "4  0.000000          0.0  0.000000       0.0       0.0  0.000000      0.0   \n",
       "5  0.000000          0.0  0.000000       0.0       0.0  0.668611      0.0   \n",
       "6  0.000000          0.0  0.000000       0.0       0.0  0.000000      0.0   \n",
       "7  0.000000          0.0  0.000000       0.0       0.0  0.329341      0.0   \n",
       "8  0.553819          0.0  0.553819       0.0       0.0  0.000000      0.0   \n",
       "9  0.000000          0.0  0.000000       0.0       0.0  0.000000      0.0   \n",
       "\n",
       "   80 20  accurate model  add column  ...  use scikit  used regression  \\\n",
       "0    0.0             0.0         0.0  ...         0.0              0.0   \n",
       "1    0.0             0.0         0.0  ...         0.0              0.0   \n",
       "2    0.0             0.0         0.0  ...         0.0              0.0   \n",
       "3    0.0             0.0         0.0  ...         0.0              0.0   \n",
       "4    0.0             0.0         0.0  ...         0.0              0.0   \n",
       "5    0.0             0.0         0.0  ...         0.0              0.0   \n",
       "6    0.0             0.0         0.0  ...         0.0              0.0   \n",
       "7    0.0             0.0         0.0  ...         0.0              0.0   \n",
       "8    0.0             0.0         0.0  ...         0.0              0.0   \n",
       "9    0.0             0.0         0.0  ...         0.0              0.0   \n",
       "\n",
       "   using nearest  versicolor virginica  want predict  web site  width cm  \\\n",
       "0            0.0                   0.0           0.0  0.000000       0.0   \n",
       "1            0.0                   0.0           0.0  0.000000       0.0   \n",
       "2            0.0                   0.0           0.0  0.000000       0.0   \n",
       "3            0.0                   0.0           0.0  0.000000       0.0   \n",
       "4            0.0                   0.0           0.0  0.000000       0.0   \n",
       "5            0.0                   0.0           0.0  0.000000       0.0   \n",
       "6            0.0                   0.0           0.0  0.000000       0.0   \n",
       "7            0.0                   0.0           0.0  0.000000       0.0   \n",
       "8            0.0                   0.0           0.0  0.000000       0.0   \n",
       "9            0.0                   0.0           0.0  0.484482       0.0   \n",
       "\n",
       "   world datasets     xs ys  years experience  \n",
       "0         0.00000  0.000000               0.0  \n",
       "1         0.00000  0.000000               0.0  \n",
       "2         0.00000  0.000000               0.0  \n",
       "3         0.00000  0.000000               0.0  \n",
       "4         0.00000  0.420631               0.0  \n",
       "5         0.00000  0.000000               0.0  \n",
       "6         0.32221  0.000000               0.0  \n",
       "7         0.00000  0.000000               0.0  \n",
       "8         0.00000  0.000000               0.0  \n",
       "9         0.00000  0.000000               0.0  \n",
       "\n",
       "[10 rows x 187 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(2, 2), min_df=0.02, max_df=0.5, stop_words='english')\n",
    "word_matrix = vectorizer.fit_transform(df[0])\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "wm_df = pd.DataFrame(data=word_matrix.toarray(), columns=feature_names)\n",
    "wm_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the sparse word matrix into a coordinate matrix that includes only non-zero values (weights) and the rows and columns in which they appear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 50)\t0.36506424222075046\n",
      "  (0, 19)\t0.6833098830012316\n",
      "  (0, 36)\t0.36506424222075046\n",
      "  (0, 120)\t0.36506424222075046\n",
      "  (0, 157)\t0.36506424222075046\n",
      "  (1, 171)\t0.294834738214157\n",
      "  (1, 92)\t0.37713908497127435\n",
      "  (1, 16)\t0.37713908497127435\n",
      "  (1, 12)\t0.4029796661571696\n",
      "  (1, 78)\t0.31487825015322757\n",
      "  (1, 70)\t0.4029796661571696\n",
      "  (1, 69)\t0.4029796661571696\n",
      "  (1, 89)\t0.20561748925677317\n",
      "  (2, 77)\t0.25926713814851615\n",
      "  (2, 81)\t0.25055595725128127\n",
      "  (2, 170)\t0.2805439761927484\n",
      "  (2, 20)\t0.3318088331784477\n",
      "  (2, 171)\t0.2427635404044369\n",
      "  (2, 78)\t0.25926713814851615\n",
      "  (2, 89)\t0.6772123252964592\n",
      "  (2, 19)\t0.31053199513421553\n",
      "  (3, 89)\t1.0\n",
      "  (4, 80)\t0.42063102930041807\n",
      "  (4, 185)\t0.42063102930041807\n",
      "  (4, 132)\t0.42063102930041807\n",
      "  :\t:\n",
      "  (94, 143)\t0.20842628503675406\n",
      "  (94, 38)\t0.19506120289470322\n",
      "  (94, 76)\t0.3524483552000396\n",
      "  (94, 164)\t0.296128858229556\n",
      "  (94, 101)\t0.20842628503675406\n",
      "  (94, 174)\t0.14402207016328555\n",
      "  (94, 82)\t0.47216145691600925\n",
      "  (94, 25)\t0.1846944397962372\n",
      "  (94, 90)\t0.16285909545796898\n",
      "  (94, 89)\t0.10634801957391875\n",
      "  (95, 26)\t0.27890153642947546\n",
      "  (95, 142)\t0.27890153642947546\n",
      "  (95, 107)\t0.4081092342194724\n",
      "  (95, 139)\t0.2610173144693383\n",
      "  (95, 178)\t0.27890153642947546\n",
      "  (95, 149)\t0.24714523420147425\n",
      "  (95, 93)\t0.19812950541906302\n",
      "  (95, 164)\t0.39625901083812604\n",
      "  (95, 174)\t0.19272030224599934\n",
      "  (95, 77)\t0.43585339475520046\n",
      "  (95, 78)\t0.21792669737760023\n",
      "  (96, 56)\t0.6153561539132565\n",
      "  (96, 73)\t0.5758971886382342\n",
      "  (96, 93)\t0.4371442767660756\n",
      "  (96, 89)\t0.3139810714841378\n"
     ]
    }
   ],
   "source": [
    "coo_matrix = word_matrix.tocoo()\n",
    "print(coo_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tuples from the column numbers and weights in the coordinate matrix. Then sort the tuples in descending order based on the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89, 1.0) => machine learning\n",
      "(109, 1.0) => neural networks\n",
      "(174, 1.0) => unsupervised learning\n",
      "(87, 1.0) => look like\n",
      "(44, 1.0) => data points\n",
      "(40, 1.0) => customer ids\n",
      "(51, 1.0) => elbow distinct\n",
      "(15, 1.0) => average age\n",
      "(164, 1.0) => supervised learning\n",
      "(107, 1.0) => nearest neighbors\n",
      "(107, 1.0) => nearest neighbors\n",
      "(71, 1.0) => iris dataset\n",
      "(91, 1.0) => making predictions\n",
      "(114, 1.0) => number neighbors\n",
      "(37, 0.921075466800783) => coordinate pairs\n",
      "(169, 0.8907478931991815) => today fact\n",
      "(28, 0.816496580927726) => cluster centroids\n",
      "(39, 0.8152319881530452) => customer data\n",
      "(65, 0.8024943623495188) => image classification\n",
      "(0, 0.7948939519153183) => 000 000\n",
      "(186, 0.7906850776766574) => years experience\n",
      "(107, 0.7850172237596516) => nearest neighbors\n",
      "(109, 0.7811345963491914) => neural networks\n",
      "(107, 0.7658695380497491) => nearest neighbors\n",
      "(116, 0.7484307798581197) => open source\n",
      "(7, 0.7241459491909964) => 80 20\n",
      "(93, 0.7168242079334923) => means clustering\n",
      "(93, 0.7168242079334923) => means clustering\n",
      "(112, 0.7071067811865476) => number clusters\n",
      "(145, 0.7071067811865476) => right number\n",
      "(51, 0.7071067811865475) => elbow distinct\n",
      "(137, 0.7071067811865475) => real life\n",
      "(37, 0.7020697649777701) => coordinate pairs\n",
      "(174, 0.6972539386195831) => unsupervised learning\n",
      "(174, 0.6972539386195831) => unsupervised learning\n",
      "(19, 0.6833098830012316) => cat dog\n",
      "(170, 0.6801256079913934) => train machine\n",
      "(89, 0.6772123252964592) => machine learning\n",
      "(5, 0.6686113825006871) => 1s 0s\n",
      "(149, 0.6632129128424497) => scikit learn\n",
      "(138, 0.6503674936951619) => real world\n",
      "(5, 0.6503674936951619) => 1s 0s\n",
      "(42, 0.6493278606761229) => customers high\n",
      "(89, 0.6314713280271422) => machine learning\n",
      "(27, 0.6280380794414833) => classify flowers\n",
      "(179, 0.6280380794414833) => using nearest\n",
      "(126, 0.6280380794414833) => predict called\n",
      "(111, 0.6280380794414833) => non zero\n",
      "(76, 0.6263950754614238) => labeled data\n",
      "(63, 0.6212819121490678) => gender column\n",
      "(174, 0.6201260888440915) => unsupervised learning\n",
      "(83, 0.6187948940433332) => learning subset\n",
      "(56, 0.6153561539132565) => feel free\n",
      "(120, 0.608057211040265) => photo contains\n",
      "(81, 0.6074253494015961) => learning model\n",
      "(30, 0.6028332558511378) => cluster counts\n",
      "(34, 0.5814429648311781) => column contains\n",
      "(93, 0.5791345314277445) => means clustering\n",
      "(73, 0.5758971886382342) => jupyter notebook\n",
      "(112, 0.5641773061901358) => number clusters\n",
      "(145, 0.5641773061901358) => right number\n",
      "(163, 0.5620317766861446) => start creating\n",
      "(82, 0.5591991909569721) => learning models\n",
      "(123, 0.5575613827858584) => points nearest\n",
      "(39, 0.55534282496716) => customer data\n",
      "(182, 0.55534282496716) => web site\n",
      "(41, 0.5548129713731844) => customers clusters\n",
      "(2, 0.5538192374916028) => 000 rows\n",
      "(0, 0.5538192374916028) => 000 000\n",
      "(57, 0.5538192374916028) => finding patterns\n",
      "(160, 0.5490059385756062) => spending scores\n",
      "(113, 0.5317216832350273) => number customer\n",
      "(171, 0.5314052266263299) => training data\n",
      "(73, 0.5259921722738293) => jupyter notebook\n",
      "(5, 0.525293122251498) => 1s 0s\n",
      "(126, 0.5212059025759358) => predict called\n",
      "(74, 0.5212059025759358) => kneighborsclassifier fit\n",
      "(150, 0.5192362640755884) => segment customers\n",
      "(56, 0.5188338371417472) => feel free\n",
      "(98, 0.5188338371417472) => model score\n",
      "(58, 0.5188338371417472) => fitting training\n",
      "(108, 0.5031973345147025) => negative sentiment\n",
      "(60, 0.4980376833201554) => following statements\n",
      "(159, 0.4976256767169794) => spending score\n",
      "(66, 0.4976256767169794) => income spending\n",
      "(68, 0.4946083035296912) => incomes spending\n",
      "(14, 0.4946083035296912) => annual incomes\n",
      "(125, 0.48448180871873686) => positive sentiment\n",
      "(108, 0.48448180871873686) => negative sentiment\n",
      "(182, 0.48448180871873686) => web site\n",
      "(151, 0.48448180871873686) => sentiment analysis\n",
      "(159, 0.48091966182842655) => spending score\n",
      "(66, 0.48091966182842655) => income spending\n",
      "(172, 0.47558217092101424) => training testing\n",
      "(162, 0.47558217092101424) => split dataset\n",
      "(161, 0.47440877477416565) => split 80\n",
      "(7, 0.47440877477416565) => 80 20\n",
      "(162, 0.47440877477416565) => split dataset\n",
      "(82, 0.47216145691600925) => learning models\n",
      "(122, 0.47211789302347673) => points closest\n",
      "(52, 0.47211789302347673) => elbow method\n",
      "(30, 0.47211789302347673) => cluster counts\n",
      "(13, 0.4711787594126524) => annual income\n",
      "(59, 0.46909371140411427) => following code\n",
      "(82, 0.46726527902845216) => learning models\n",
      "(32, 0.4649471137974214) => cm petal\n",
      "(183, 0.4649471137974214) => width cm\n",
      "(84, 0.4649471137974214) => length cm\n",
      "(107, 0.4594957470346231) => nearest neighbors\n",
      "(171, 0.4594957470346231) => training data\n",
      "(13, 0.45536060585223137) => annual income\n",
      "(89, 0.4544977346051569) => machine learning\n",
      "(98, 0.45287067060577946) => model score\n",
      "(17, 0.45287067060577946) => calling model\n",
      "(46, 0.45287067060577946) => data split\n",
      "(166, 0.45287067060577946) => test data\n",
      "(175, 0.45003039762442426) => use following\n",
      "(100, 0.44871795276101695) => models contrast\n",
      "(91, 0.4450860423807326) => making predictions\n",
      "(145, 0.44184390709181726) => right number\n",
      "(127, 0.43867339594544896) => predict class\n",
      "(93, 0.4371442767660756) => means clustering\n",
      "(77, 0.43585339475520046) => learning algorithm\n",
      "(89, 0.42924794182797193) => machine learning\n",
      "(96, 0.423830889412613) => model accuracy\n",
      "(177, 0.42265519253665274) => use scikit\n",
      "(86, 0.42265519253665274) => ll use\n",
      "(116, 0.42265519253665274) => open source\n",
      "(80, 0.42063102930041807) => learning machine\n",
      "(185, 0.42063102930041807) => xs ys\n",
      "(132, 0.42063102930041807) => predictions train\n",
      "(57, 0.42063102930041807) => finding patterns\n",
      "(60, 0.4203916165174786) => following statements\n",
      "(43, 0.419944459551145) => data data\n",
      "(42, 0.41829377948173574) => customers high\n",
      "(160, 0.4181907359155329) => spending scores\n",
      "(59, 0.4181907359155329) => following code\n",
      "(29, 0.4169661580146619) => cluster containing\n",
      "(106, 0.4169661580146619) => named cluster\n",
      "(35, 0.4169661580146619) => column named\n",
      "(41, 0.4169661580146619) => customers clusters\n",
      "(89, 0.4104431778683697) => machine learning\n",
      "(21, 0.408248290463863) => centroids red\n",
      "(31, 0.408248290463863) => clusters based\n",
      "(107, 0.4081092342194724) => nearest neighbors\n",
      "(107, 0.40793240487691845) => nearest neighbors\n",
      "(77, 0.40725727959840985) => learning algorithm\n",
      "(164, 0.4049646495686499) => supervised learning\n",
      "(12, 0.4029796661571696) => algorithms build\n",
      "(70, 0.4029796661571696) => inputs outputs\n",
      "(69, 0.4029796661571696) => input output\n",
      "(170, 0.4021041632873168) => train machine\n",
      "(175, 0.4011960480211785) => use following\n",
      "(93, 0.3992630494984059) => means clustering\n",
      "(164, 0.39625901083812604) => supervised learning\n",
      "(53, 0.3953946288352284) => examine dataset\n",
      "(164, 0.3945565493643018) => supervised learning\n",
      "(93, 0.3945112696666389) => means clustering\n",
      "(89, 0.3924847083509714) => machine learning\n",
      "(88, 0.3914711993964243) => low spending\n",
      "(67, 0.3914711993964243) => incomes low\n",
      "(64, 0.3914711993964243) => high incomes\n",
      "(105, 0.3905672981745957) => models use\n",
      "(9, 0.3902287100419238) => add column\n",
      "(150, 0.3902287100419238) => segment customers\n",
      "(167, 0.38952304454583797) => thousands columns\n",
      "(147, 0.38952304454583797) => rows thousands\n",
      "(148, 0.38952304454583797) => rules predicting\n",
      "(154, 0.38952304454583797) => set rules\n",
      "(53, 0.38952304454583797) => examine dataset\n",
      "(59, 0.3893841091489479) => following code\n",
      "(46, 0.38528360365633474) => data split\n",
      "(166, 0.38528360365633474) => test data\n",
      "(172, 0.38528360365633474) => training testing\n",
      "(177, 0.38528360365633474) => use scikit\n",
      "(175, 0.38481142396457785) => use following\n",
      "(174, 0.38374057901571057) => unsupervised learning\n",
      "(107, 0.3813333990447931) => nearest neighbors\n",
      "(171, 0.3813333990447931) => training data\n",
      "(32, 0.3778040229857592) => cm petal\n",
      "(183, 0.3778040229857592) => width cm\n",
      "(84, 0.3778040229857592) => length cm\n",
      "(92, 0.37713908497127435) => mathematical models\n",
      "(16, 0.37713908497127435) => build mathematical\n",
      "(149, 0.37453080353450774) => scikit learn\n",
      "(143, 0.37042930295316956) => require labeled\n",
      "(79, 0.37042930295316956) => learning doesn\n",
      "(95, 0.37027104264713323) => ml models\n",
      "(34, 0.37004042894639644) => column contains\n",
      "(45, 0.37004042894639644) => data scientists\n",
      "(44, 0.36890113448870887) => data points\n",
      "(10, 0.36728896654030335) => age annual\n",
      "(62, 0.36728896654030335) => gender age\n",
      "(52, 0.36728896654030335) => elbow method\n",
      "(31, 0.36728896654030335) => clusters based\n",
      "(133, 0.36569782619718466) => predictive model\n",
      "(178, 0.36569782619718466) => used regression\n",
      "(135, 0.36569782619718466) => produces accurate\n",
      "(11, 0.36569782619718466) => algorithm produces\n",
      "(50, 0.36506424222075046) => dog picture\n",
      "(36, 0.36506424222075046) => contains cat\n",
      "(120, 0.36506424222075046) => photo contains\n",
      "(157, 0.36506424222075046) => software developers\n",
      "(117, 0.3650350525081355) => pandas dataframe\n",
      "(136, 0.3650350525081355) => promotion increase\n",
      "(165, 0.3650350525081355) => target promotion\n",
      "(115, 0.3650350525081355) => ones target\n",
      "(176, 0.3650350525081355) => use means\n",
      "(163, 0.3650350525081355) => start creating\n",
      "(86, 0.3650350525081355) => ll use\n",
      "(94, 0.3645453528614191) => millions rows\n",
      "(58, 0.36316192270482417) => fitting training\n",
      "(74, 0.36316192270482417) => kneighborsclassifier fit\n",
      "(4, 0.36316192270482417) => 120 rows\n",
      "(99, 0.36316192270482417) => model train\n",
      "(96, 0.3605777609650243) => model accuracy\n",
      "(25, 0.3592150447414065) => classification models\n",
      "(81, 0.35912228419390096) => learning model\n",
      "(55, 0.3576534441796459) => experience earn\n",
      "(3, 0.3576534441796459) => 10 years\n",
      "(186, 0.3576534441796459) => years experience\n",
      "(160, 0.35366689605091906) => spending scores\n",
      "(59, 0.35366689605091906) => following code\n",
      "(89, 0.353217262931838) => machine learning\n",
      "(76, 0.3524483552000396) => labeled data\n",
      "(176, 0.35103488248888504) => use means\n",
      "(21, 0.35103488248888504) => centroids red\n",
      "(28, 0.35103488248888504) => cluster centroids\n",
      "(90, 0.3506170053816594) => make predictions\n",
      "(75, 0.3503741836510015) => label column\n",
      "(110, 0.34893110118118054) => new point\n",
      "(173, 0.34893110118118054) => triangles ellipses\n",
      "(24, 0.34893110118118054) => classification model\n",
      "(140, 0.34893110118118054) => regression model\n",
      "(123, 0.3489297683991095) => points nearest\n",
      "(137, 0.3489297683991095) => real life\n",
      "(43, 0.34667597423592683) => data data\n",
      "(8, 0.3465748543252808) => accurate model\n",
      "(135, 0.3465748543252808) => produces accurate\n",
      "(11, 0.3465748543252808) => algorithm produces\n",
      "(144, 0.3465748543252808) => right goal\n",
      "(87, 0.3465748543252808) => look like\n",
      "(184, 0.3465748543252808) => world datasets\n",
      "(185, 0.3465748543252808) => xs ys\n",
      "(63, 0.3461266237899375) => gender column\n",
      "(134, 0.3461266237899375) => previous example\n",
      "(40, 0.3461266237899375) => customer ids\n",
      "(68, 0.3461266237899375) => incomes spending\n",
      "(14, 0.3461266237899375) => annual incomes\n",
      "(89, 0.34583925596958626) => machine learning\n",
      "(159, 0.3437370080777971) => spending score\n",
      "(66, 0.3437370080777971) => income spending\n",
      "(112, 0.3437370080777971) => number clusters\n",
      "(139, 0.3422478976748156) => regression classification\n",
      "(45, 0.3422478976748156) => data scientists\n",
      "(89, 0.34132134197575703) => machine learning\n",
      "(175, 0.3392943669613113) => use following\n",
      "(99, 0.3388967261939198) => model train\n",
      "(144, 0.3388967261939198) => right goal\n",
      "(121, 0.3388967261939198) => pictured figure\n",
      "(82, 0.33883653763191773) => learning models\n",
      "(23, 0.3377963988498603) => class setosa\n",
      "(47, 0.3377963988498603) => dataframe add\n",
      "(117, 0.3377963988498603) => pandas dataframe\n",
      "(61, 0.334469506798476) => future inputs\n",
      "(12, 0.334469506798476) => algorithms build\n",
      "(70, 0.334469506798476) => inputs outputs\n",
      "(69, 0.334469506798476) => input output\n",
      "(157, 0.334469506798476) => software developers\n",
      "(20, 0.3318088331784477) => cats dogs\n",
      "(5, 0.3293412736749664) => 1s 0s\n",
      "(89, 0.3288106624343692) => machine learning\n",
      "(90, 0.32867058462103543) => make predictions\n",
      "(45, 0.3265563185169865) => data scientists\n",
      "(92, 0.3265563185169865) => mathematical models\n",
      "(16, 0.3265563185169865) => build mathematical\n",
      "(138, 0.32575683141469747) => real world\n",
      "(13, 0.32546868983697497) => annual income\n",
      "(150, 0.3239316748290256) => segment customers\n",
      "(167, 0.32220997215672187) => thousands columns\n",
      "(147, 0.32220997215672187) => rows thousands\n",
      "(184, 0.32220997215672187) => world datasets\n",
      "(148, 0.32220997215672187) => rules predicting\n",
      "(154, 0.32220997215672187) => set rules\n",
      "(48, 0.32220997215672187) => dataset like\n",
      "(156, 0.32220997215672187) => small dataset\n",
      "(81, 0.31915598912429477) => learning model\n",
      "(91, 0.3171653856268933) => making predictions\n",
      "(180, 0.31613561543609253) => versicolor virginica\n",
      "(155, 0.31613561543609253) => setosa versicolor\n",
      "(9, 0.31613561543609253) => add column\n",
      "(73, 0.31613561543609253) => jupyter notebook\n",
      "(78, 0.31487825015322757) => learning algorithms\n",
      "(89, 0.3139810714841378) => machine learning\n",
      "(92, 0.31302205629296714) => mathematical models\n",
      "(16, 0.31302205629296714) => build mathematical\n",
      "(19, 0.31053199513421553) => cat dog\n",
      "(75, 0.30919990773399797) => label column\n",
      "(88, 0.30384525050233874) => low spending\n",
      "(67, 0.30384525050233874) => incomes low\n",
      "(64, 0.30384525050233874) => high incomes\n",
      "(94, 0.30154864940607595) => millions rows\n",
      "(90, 0.30105098872338704) => make predictions\n",
      "(93, 0.30025099657800175) => means clustering\n",
      "(164, 0.296128858229556) => supervised learning\n",
      "(127, 0.2950208335473601) => predict class\n",
      "(171, 0.294834738214157) => training data\n",
      "(138, 0.29302862961621795) => real world\n",
      "(160, 0.2926496512284769) => spending scores\n",
      "(5, 0.2926496512284769) => 1s 0s\n",
      "(174, 0.29205373872905044) => unsupervised learning\n",
      "(89, 0.2908678926907333) => machine learning\n",
      "(90, 0.2893205483615344) => make predictions\n",
      "(127, 0.2865367813581249) => predict class\n",
      "(76, 0.2865367813581249) => labeled data\n",
      "(170, 0.2865367813581249) => train machine\n",
      "(77, 0.2857471512046414) => learning algorithm\n",
      "(78, 0.2857471512046414) => learning algorithms\n",
      "(59, 0.2856064558895137) => following code\n",
      "(170, 0.2856064558895137) => train machine\n",
      "(18, 0.2850288823096551) => card transaction\n",
      "(128, 0.2850288823096551) => predict credit\n",
      "(54, 0.2850288823096551) => example predict\n",
      "(131, 0.2850288823096551) => predictions example\n",
      "(102, 0.2850288823096551) => models make\n",
      "(168, 0.2850288823096551) => time trained\n",
      "(77, 0.2837656595282834) => learning algorithm\n",
      "(89, 0.28335970009458383) => machine learning\n",
      "(89, 0.2825823004943147) => machine learning\n",
      "(171, 0.28188764834084284) => training data\n",
      "(29, 0.281032929557429) => cluster containing\n",
      "(106, 0.281032929557429) => named cluster\n",
      "(35, 0.281032929557429) => column named\n",
      "(47, 0.281032929557429) => dataframe add\n",
      "(136, 0.281032929557429) => promotion increase\n",
      "(165, 0.281032929557429) => target promotion\n",
      "(115, 0.281032929557429) => ones target\n",
      "(170, 0.2805439761927484) => train machine\n",
      "(81, 0.279719101225497) => learning model\n",
      "(26, 0.27890153642947546) => classification problems\n",
      "(142, 0.27890153642947546) => regression problems\n",
      "(178, 0.27890153642947546) => used regression\n",
      "(181, 0.2787806913929292) => want predict\n",
      "(110, 0.2787806913929292) => new point\n",
      "(173, 0.2787806913929292) => triangles ellipses\n",
      "(121, 0.2787806913929292) => pictured figure\n",
      "(122, 0.2787806913929292) => points closest\n",
      "(44, 0.2742898930730017) => data points\n",
      "(81, 0.2742313467332772) => learning model\n",
      "(44, 0.272646050883166) => data points\n",
      "(44, 0.27264500948053055) => data points\n",
      "(138, 0.27242815054651454) => real world\n",
      "(77, 0.2708049384171455) => learning algorithm\n",
      "(124, 0.2674981207831729) => positive negative\n",
      "(151, 0.2674981207831729) => sentiment analysis\n",
      "(20, 0.2674981207831729) => cats dogs\n",
      "(50, 0.2674981207831729) => dog picture\n",
      "(38, 0.26675175174402743) => credit card\n",
      "(55, 0.26356169255888584) => experience earn\n",
      "(3, 0.26356169255888584) => 10 years\n",
      "(6, 0.26356169255888584) => 20 data\n",
      "(181, 0.26356169255888584) => want predict\n",
      "(164, 0.2631501264798457) => supervised learning\n",
      "(9, 0.2630120346041178) => add column\n",
      "(88, 0.2630120346041178) => low spending\n",
      "(67, 0.2630120346041178) => incomes low\n",
      "(64, 0.2630120346041178) => high incomes\n",
      "(78, 0.2613461220875633) => learning algorithms\n",
      "(139, 0.2610173144693383) => regression classification\n",
      "(164, 0.25978892179963364) => supervised learning\n",
      "(158, 0.2595226282172634) => species iris\n",
      "(71, 0.2595226282172634) => iris dataset\n",
      "(114, 0.2595226282172634) => number neighbors\n",
      "(27, 0.2595226282172634) => classify flowers\n",
      "(179, 0.2595226282172634) => using nearest\n",
      "(146, 0.2595226282172634) => row contains\n",
      "(93, 0.2593180924707702) => means clustering\n",
      "(77, 0.25926713814851615) => learning algorithm\n",
      "(78, 0.25926713814851615) => learning algorithms\n",
      "(15, 0.2569355080060179) => average age\n",
      "(10, 0.2569355080060179) => age annual\n",
      "(62, 0.2569355080060179) => gender age\n",
      "(134, 0.2569355080060179) => previous example\n",
      "(113, 0.2569355080060179) => number customer\n",
      "(174, 0.25596577250825425) => unsupervised learning\n",
      "(82, 0.2559081770893565) => learning models\n",
      "(81, 0.2559081770893565) => learning model\n",
      "(81, 0.25507729634293486) => learning model\n",
      "(168, 0.25159866725735125) => time trained\n",
      "(124, 0.25159866725735125) => positive negative\n",
      "(79, 0.25159866725735125) => learning doesn\n",
      "(111, 0.25159866725735125) => non zero\n",
      "(146, 0.25159866725735125) => row contains\n",
      "(1, 0.25159866725735125) => 000 columns\n",
      "(85, 0.25159866725735125) => like figure\n",
      "(125, 0.25159866725735125) => positive sentiment\n",
      "(48, 0.25159866725735125) => dataset like\n",
      "(81, 0.25055595725128127) => learning model\n",
      "(93, 0.24937247941604146) => means clustering\n",
      "(60, 0.24903394252673902) => following statements\n",
      "(89, 0.2472033739302222) => machine learning\n",
      "(149, 0.24714523420147425) => scikit learn\n",
      "(171, 0.244710187037293) => training data\n",
      "(180, 0.2428810551871007) => versicolor virginica\n",
      "(155, 0.2428810551871007) => setosa versicolor\n",
      "(119, 0.2428810551871007) => petal width\n",
      "(118, 0.2428810551871007) => petal length\n",
      "(153, 0.2428810551871007) => sepal width\n",
      "(152, 0.2428810551871007) => sepal length\n",
      "(139, 0.2428810551871007) => regression classification\n",
      "(171, 0.2427635404044369) => training data\n",
      "(89, 0.24266239746678767) => machine learning\n",
      "(4, 0.24138198306366546) => 120 rows\n",
      "(161, 0.24138198306366546) => split 80\n",
      "(6, 0.24138198306366546) => 20 data\n",
      "(8, 0.24138198306366546) => accurate model\n",
      "(156, 0.24138198306366546) => small dataset\n",
      "(76, 0.24099158303576915) => labeled data\n",
      "(164, 0.24074962658342944) => supervised learning\n",
      "(160, 0.23761300970771979) => spending scores\n",
      "(49, 0.23546520859050393) => datasets like\n",
      "(94, 0.23546520859050393) => millions rows\n",
      "(13, 0.23355201648548088) => annual income\n",
      "(33, 0.2324735568987107) => cm sepal\n",
      "(72, 0.2324735568987107) => iris sepal\n",
      "(129, 0.2324735568987107) => predict method\n",
      "(149, 0.22997284831220866) => scikit learn\n",
      "(25, 0.22997284831220866) => classification models\n",
      "(175, 0.22795674859810847) => use following\n",
      "(138, 0.22616934488974255) => real world\n",
      "(96, 0.2259036568502125) => model accuracy\n",
      "(43, 0.2259036568502125) => data data\n",
      "(49, 0.2259036568502125) => datasets like\n",
      "(75, 0.2229511258351221) => label column\n",
      "(90, 0.2227144524701415) => make predictions\n",
      "(78, 0.21792669737760023) => learning algorithms\n",
      "(44, 0.21783227208311767) => data points\n",
      "(78, 0.21783227208311767) => learning algorithms\n",
      "(119, 0.21756647268302212) => petal width\n",
      "(118, 0.21756647268302212) => petal length\n",
      "(153, 0.21756647268302212) => sepal width\n",
      "(152, 0.21756647268302212) => sepal length\n",
      "(89, 0.21565678571193686) => machine learning\n",
      "(82, 0.21523141432751086) => learning models\n",
      "(26, 0.20842628503675406) => classification problems\n",
      "(142, 0.20842628503675406) => regression problems\n",
      "(130, 0.20842628503675406) => predict numeric\n",
      "(141, 0.20842628503675406) => regression models\n",
      "(18, 0.20842628503675406) => card transaction\n",
      "(128, 0.20842628503675406) => predict credit\n",
      "(54, 0.20842628503675406) => example predict\n",
      "(131, 0.20842628503675406) => predictions example\n",
      "(143, 0.20842628503675406) => require labeled\n",
      "(101, 0.20842628503675406) => models fall\n",
      "(44, 0.20594052635895854) => data points\n",
      "(89, 0.20561748925677317) => machine learning\n",
      "(77, 0.20278450232361594) => learning algorithm\n",
      "(24, 0.20268573701342169) => classification model\n",
      "(130, 0.20268573701342169) => predict numeric\n",
      "(97, 0.20268573701342169) => model predict\n",
      "(140, 0.20268573701342169) => regression model\n",
      "(141, 0.20268573701342169) => regression models\n",
      "(100, 0.20268573701342169) => models contrast\n",
      "(103, 0.20268573701342169) => models purpose\n",
      "(22, 0.20268573701342169) => class category\n",
      "(36, 0.20268573701342169) => contains cat\n",
      "(89, 0.19928416736823745) => machine learning\n",
      "(22, 0.19872348797882958) => class category\n",
      "(104, 0.19872348797882958) => models trained\n",
      "(65, 0.19872348797882958) => image classification\n",
      "(1, 0.19872348797882958) => 000 columns\n",
      "(85, 0.19872348797882958) => like figure\n",
      "(2, 0.19872348797882958) => 000 rows\n",
      "(93, 0.19812950541906302) => means clustering\n",
      "(164, 0.1980436580349655) => supervised learning\n",
      "(174, 0.19695428376188318) => unsupervised learning\n",
      "(95, 0.19528364908729784) => ml models\n",
      "(83, 0.19528364908729784) => learning subset\n",
      "(169, 0.19528364908729784) => today fact\n",
      "(80, 0.19528364908729784) => learning machine\n",
      "(38, 0.19506120289470322) => credit card\n",
      "(174, 0.19272030224599934) => unsupervised learning\n",
      "(107, 0.18987629544872386) => nearest neighbors\n",
      "(19, 0.18968876053452507) => cat dog\n",
      "(33, 0.1889020114928796) => cm sepal\n",
      "(72, 0.1889020114928796) => iris sepal\n",
      "(129, 0.1889020114928796) => predict method\n",
      "(17, 0.1889020114928796) => calling model\n",
      "(23, 0.1889020114928796) => class setosa\n",
      "(158, 0.1889020114928796) => species iris\n",
      "(133, 0.1889020114928796) => predictive model\n",
      "(97, 0.1889020114928796) => model predict\n",
      "(49, 0.1859805859023302) => datasets like\n",
      "(34, 0.1859805859023302) => column contains\n",
      "(89, 0.18530077076173027) => machine learning\n",
      "(61, 0.18513552132356662) => future inputs\n",
      "(102, 0.18513552132356662) => models make\n",
      "(103, 0.18513552132356662) => models purpose\n",
      "(101, 0.18513552132356662) => models fall\n",
      "(105, 0.18513552132356662) => models use\n",
      "(104, 0.18513552132356662) => models trained\n",
      "(132, 0.18513552132356662) => predictions train\n",
      "(25, 0.1846944397962372) => classification models\n",
      "(89, 0.17803959597428673) => machine learning\n",
      "(180, 0.17678889965597402) => versicolor virginica\n",
      "(155, 0.17678889965597402) => setosa versicolor\n",
      "(119, 0.17678889965597402) => petal width\n",
      "(118, 0.17678889965597402) => petal length\n",
      "(153, 0.17678889965597402) => sepal width\n",
      "(152, 0.17678889965597402) => sepal length\n",
      "(171, 0.17660393256277382) => training data\n",
      "(25, 0.1760964231557068) => classification models\n",
      "(75, 0.1760964231557068) => label column\n",
      "(38, 0.17326393108980823) => credit card\n",
      "(89, 0.17235819383600945) => machine learning\n",
      "(127, 0.17137055103268556) => predict class\n",
      "(60, 0.16739324017077492) => following statements\n",
      "(90, 0.16285909545796898) => make predictions\n",
      "(127, 0.15971642739998926) => predict class\n",
      "(76, 0.1565318644145256) => labeled data\n",
      "(175, 0.15322577468545287) => use following\n",
      "(82, 0.1530523415308461) => learning models\n",
      "(78, 0.15258976785236306) => learning algorithms\n",
      "(171, 0.14829233638996714) => training data\n",
      "(90, 0.14760331556308368) => make predictions\n",
      "(82, 0.14746286638570827) => learning models\n",
      "(174, 0.14402207016328555) => unsupervised learning\n",
      "(164, 0.14398638797073135) => supervised learning\n",
      "(89, 0.13648900079958165) => machine learning\n",
      "(89, 0.1283764184807032) => machine learning\n",
      "(174, 0.12792820750548461) => unsupervised learning\n",
      "(89, 0.10634801957391875) => machine learning\n"
     ]
    }
   ],
   "source": [
    "tuples = list(zip(coo_matrix.col, coo_matrix.data))\n",
    "sorted_tuples = sorted(tuples, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for _, tuple in enumerate(sorted_tuples):\n",
    "    print(f'{tuple} => {feature_names[tuple[0]]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the top keywords by weight and use `set` to eliminate duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data points', 'unsupervised learning', 'neural networks', 'machine learning', 'look like'}\n"
     ]
    }
   ],
   "source": [
    "keywords = []\n",
    "num_keywords = 5\n",
    "\n",
    "for tuple in sorted_tuples[:num_keywords]:\n",
    "    keywords.append(feature_names[tuple[0]])\n",
    "    \n",
    "print(set(keywords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keyword extraction sometimes works better when you sum all the values for a given word and select the words yielding the highest sums rather than the words with the highest individual values. Sort keywords based on that criterion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machine learning         8.552673\n",
      "nearest neighbors        5.397634\n",
      "unsupervised learning    4.608019\n",
      "means clustering         4.250773\n",
      "supervised learning      3.597628\n",
      "                           ...   \n",
      "class category           0.401409\n",
      "models fall              0.393562\n",
      "model predict            0.391588\n",
      "models purpose           0.387821\n",
      "models trained           0.383859\n",
      "Length: 187, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "summed_weights = pd.Series(dtype='float32')\n",
    "\n",
    "for col_name, col_data in wm_df.iteritems():\n",
    "    summed_weights = summed_weights.append(pd.Series({ col_name: np.sum(col_data) }))\n",
    "    \n",
    "sorted_summed_weights = summed_weights.sort_values(ascending=False)\n",
    "print(sorted_summed_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the top keywords by summed weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['machine learning', 'nearest neighbors', 'unsupervised learning', 'means clustering', 'supervised learning']\n"
     ]
    }
   ],
   "source": [
    "keywords = []\n",
    "\n",
    "for idx, _ in sorted_summed_weights[:num_keywords].items():\n",
    "    keywords.append(idx)\n",
    "    \n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you read **chapter-1.txt**, you'll see that these keywords highlight some of the most important concepts introduced in the chapter."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
